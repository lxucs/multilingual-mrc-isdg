basic {
  data_dir = /home/ubuntu/clsp_data_dir  # Edit this
  download_dir = ${basic.data_dir}/download  # dir that contains downloaded dataset
  log_root = ${basic.data_dir}
}

#*************** Dataset-specific config ***************

dataset = ${basic} {
  max_segment_len = 384
  doc_stride = 128
  max_query_len = 64
  max_answer_len = 30
  n_best_predictions = 10
  version_2_with_negative = false  # Only true for squad 2
  null_score_diff_threshold = 0.0
  max_node_depth = 8

  use_graph_path = false  # [seq len, seq len, path len]
  use_root_path = false  # [seq len, path len]
  use_graph_rel = false  # [seq len, seq len]
}

dataset_rel = ${dataset} {
  use_graph_rel = true
}

dataset_rel_root = ${dataset_rel} {
  use_root_path = true
}

#*************** Model-specific config ***************

model {
  # Learning
  num_epochs = 2
  batch_size = 16
  bert_learning_rate = 3e-5
  # task_learning_rate = 2e-4
  adam_eps = 1e-8
  adam_weight_decay = 1e-4
  warmup_ratio = 0.1
  max_grad_norm = 1
  gradient_accumulation_steps = 1

  # Model
  use_pos_feature = false
  use_depth_feature = false
  node_rel_feature = false
  feat_emb_size = 64

  # Graph
  graph_layer = 0 
  path_hidden = 0.25
  use_undirected_path = false
  use_expanded_value = true
  path_attention_heads = 4
  final_layer = 0

  # Other
  do_eval = true
  eval_frequency = 1000
  report_frequency = 100
  zero_shot = true

  # Dataset name
  train_dataset = squad
}

mbert_base = ${model}{
  model_type = bert
  pretrained = bert-base-multilingual-cased
  path_attention_heads = 3
  feat_emb_size = 48
}

mbert_feat = ${mbert_base} {
  use_pos_feature = true
}

xlmr_base = ${model}{
  model_type = xlm-roberta
  pretrained = xlm-roberta-base
  path_attention_heads = 3
}

xlmr_base_feat = ${xlmr_base} {
  use_pos_feature = true
}

xlmr_large = ${model}{
  model_type = xlm-roberta
  pretrained = xlm-roberta-large
}

xlmr_large_feat = ${xlmr_large} {
  use_pos_feature = true
}

mt5_large = ${model} {
  model_type = mt5
  pretrained = google/mt5-large
  bert_learning_rate = 1e-4
}

mt5_large_feat = ${mt5_large} {
  use_pos_feature = true
}

#*************** Experiment-specific config ***************

mbert_base_zero_shot = ${dataset} ${mbert_base} {
}

mbert_feat_zero_shot = ${dataset} ${mbert_feat} {
}

mbert_feat_rel_f1 = ${dataset_rel} ${mbert_feat} {
  graph_layer = 2
  final_layer = 1
  batch_size = 8
  gradient_accumulation_steps = 2
}

mbert_feat_rel_root_f1 = ${dataset_rel_root} ${mbert_feat} {
  graph_layer = 1
  final_layer = 1
  batch_size = 8
  gradient_accumulation_steps = 2
}

mbert_base_zero_shot_tydiqa = ${mbert_base_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

mbert_feat_zero_shot_tydiqa = ${mbert_feat_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

mbert_feat_rel_f1_tydiqa = ${mbert_feat_rel_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}

mbert_feat_rel_root_f1_tydiqa = ${mbert_feat_rel_root_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}

xlmr_large_zero_shot = ${dataset} ${xlmr_large} {
}

xlmr_large_feat_zero_shot = ${dataset} ${xlmr_large_feat} {
}

xlmr_large_feat_rel_f1 = ${dataset_rel} ${xlmr_large_feat} {
  graph_layer = 2
  final_layer = 1
  batch_size = 4
  gradient_accumulation_steps = 4
}

xlmr_large_feat_rel_root_f1 = ${dataset_rel_root} ${xlmr_large_feat} {
  graph_layer = 1
  final_layer = 1
  batch_size = 5
  gradient_accumulation_steps = 3
}

xlmr_large_feat_rel_root_f1_v2 = ${xlmr_large_feat_rel_root_f1} {
  graph_layer = 2
  final_layer = 2
  batch_size = 4
  gradient_accumulation_steps = 4
}

xlmr_large_zero_shot_tydiqa = ${xlmr_large_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

xlmr_large_feat_zero_shot_tydiqa = ${xlmr_large_feat_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

xlmr_large_feat_rel_f1_tydiqa = ${xlmr_large_feat_rel_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}

xlmr_large_feat_rel_root_f1_tydiqa = ${xlmr_large_feat_rel_root_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}

mt5_large_zero_shot = ${dataset} ${mt5_large} {
}

mt5_large_feat_zero_shot = ${dataset} ${mt5_large_feat} {
}

mt5_large_feat_rel_f1 = ${dataset_rel} ${mt5_large_feat} {
  graph_layer = 2
  final_layer = 1
  batch_size = 4
  gradient_accumulation_steps = 4
}

mt5_large_feat_rel_root_f1 = ${dataset_rel_root} ${mt5_large_feat} {
  graph_layer = 1
  final_layer = 1
  batch_size = 5
  gradient_accumulation_steps = 3
}

mt5_large_zero_shot_tydiqa = ${mt5_large_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

mt5_large_feat_zero_shot_tydiqa = ${mt5_large_feat_zero_shot} {
  train_dataset = tydiqa
  num_epochs = 4
}

mt5_large_feat_rel_f1_tydiqa = ${mt5_large_feat_rel_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}

mt5_large_feat_rel_root_f1_tydiqa = ${mt5_large_feat_rel_root_f1} {
  train_dataset = tydiqa
  num_epochs = 4
}
